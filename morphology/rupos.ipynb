{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Имена файлов с данными.\n",
    "TRAIN_FILENAME = \"train.csv\"\n",
    "TEST_FILENAME = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считывание файлов.\n",
    "from collections import namedtuple\n",
    "WordForm = namedtuple(\"WordForm\", \"word pos gram\")\n",
    "\n",
    "def get_sentences(filename, is_train):\n",
    "    sentences = []\n",
    "    with open(filename, \"r\", encoding='utf-8') as r:\n",
    "        sentence = []\n",
    "        for line in r:\n",
    "            if len(line.strip()) == 0:\n",
    "                if len(sentence) == 0:\n",
    "                    continue\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "                continue\n",
    "            if is_train:\n",
    "                word = line.strip().split(\"\\t\")[2]\n",
    "                pos = line.strip().split(\"\\t\")[3].split(\"#\")[0]\n",
    "                gram = line.strip().split(\"\\t\")[3].split(\"#\")[1]\n",
    "                sentence.append(WordForm(word, pos, gram))\n",
    "            else:\n",
    "                word = line.strip().split(\"\\t\")[2]\n",
    "                sentence.append(word)\n",
    "        if len(sentence) != 0:\n",
    "            sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = get_sentences(TRAIN_FILENAME, True)\n",
    "test = get_sentences(TEST_FILENAME, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Класс для удобной векторизации грамматических значений.\n",
    "import jsonpickle\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "def process_gram_tag(gram: str):\n",
    "    gram = gram.strip().split(\"|\")\n",
    "    return \"|\".join(sorted(gram))\n",
    "\n",
    "\n",
    "def get_empty_category():\n",
    "    return {GrammemeVectorizer.UNKNOWN_VALUE}\n",
    "\n",
    "\n",
    "class GrammemeVectorizer(object):\n",
    "    UNKNOWN_VALUE = \"Unknown\"\n",
    "\n",
    "    def __init__(self, dump_filename: str):\n",
    "        self.all_grammemes = defaultdict(get_empty_category)  # type: Dict[str, Set]\n",
    "        self.vectors = []  # type: List[List[int]]\n",
    "        self.name_to_index = {}  # type: Dict[str, int]\n",
    "        self.dump_filename = dump_filename  # type: str\n",
    "        if os.path.exists(self.dump_filename):\n",
    "            self.load()\n",
    "\n",
    "    def add_grammemes(self, pos_tag: str, gram: str) -> int:\n",
    "        gram = process_gram_tag(gram)\n",
    "        vector_name = pos_tag + '#' + gram\n",
    "        if vector_name not in self.name_to_index:\n",
    "            self.name_to_index[vector_name] = len(self.name_to_index)\n",
    "            self.all_grammemes[\"POS\"].add(pos_tag)\n",
    "            gram = gram.split(\"|\") if gram != \"_\" else []\n",
    "            for grammeme in gram:\n",
    "                category = grammeme.split(\"=\")[0]\n",
    "                value = grammeme.split(\"=\")[1]\n",
    "                self.all_grammemes[category].add(value)\n",
    "        return self.name_to_index[vector_name]\n",
    "\n",
    "    def init_possible_vectors(self) -> None:\n",
    "        self.vectors = []\n",
    "        for grammar_val, index in sorted(self.name_to_index.items(), key=lambda x: x[1]):\n",
    "            pos_tag, grammemes = grammar_val.split('#')\n",
    "            grammemes = grammemes.split(\"|\") if grammemes != \"_\" else []\n",
    "            vector = self.__build_vector(pos_tag, grammemes)\n",
    "            self.vectors.append(vector)\n",
    "\n",
    "    def get_vector(self, vector_name: str) -> List[int]:\n",
    "        if vector_name not in self.name_to_index:\n",
    "            return [0] * len(self.vectors[0])\n",
    "        return self.vectors[self.name_to_index[vector_name]]\n",
    "\n",
    "    def get_vector_by_index(self, index: int) -> List[int]:\n",
    "        return self.vectors[index] if 0 <= index < len(self.vectors) else [0] * len(self.vectors[0])\n",
    "\n",
    "    def get_ordered_grammemes(self) -> List[str]:\n",
    "        flat = []\n",
    "        sorted_grammemes = sorted(self.all_grammemes.items(), key=lambda x: x[0])\n",
    "        for category, values in sorted_grammemes:\n",
    "            for value in sorted(list(values)):\n",
    "                flat.append(category+\"=\"+value)\n",
    "        return flat\n",
    "    \n",
    "    def save(self) -> None:\n",
    "        with open(self.dump_filename, \"w\") as f:\n",
    "            f.write(jsonpickle.encode(self, f))\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.dump_filename, \"r\") as f:\n",
    "            vectorizer = jsonpickle.decode(f.read())\n",
    "            self.__dict__.update(vectorizer.__dict__)\n",
    "\n",
    "    def size(self) -> int:\n",
    "        return len(self.vectors)\n",
    "\n",
    "    def grammemes_count(self) -> int:\n",
    "        return len(self.get_ordered_grammemes())\n",
    "\n",
    "    def is_empty(self) -> int:\n",
    "        return len(self.vectors) == 0\n",
    "\n",
    "    def get_name_by_index(self, index):\n",
    "        d = {index: name for name, index in self.name_to_index.items()}\n",
    "        return d[index]\n",
    "\n",
    "    def get_index_by_name(self, name):\n",
    "        pos = name.split(\"#\")[0]\n",
    "        gram = process_gram_tag(name.split(\"#\")[1])\n",
    "        return self.name_to_index[pos + \"#\" + gram]\n",
    "\n",
    "    def __build_vector(self, pos_tag: str, grammemes: List[str]) -> List[int]:\n",
    "        vector = []\n",
    "        gram_tags = {pair.split(\"=\")[0]: pair.split(\"=\")[1] for pair in grammemes}\n",
    "        gram_tags[\"POS\"] = pos_tag\n",
    "        sorted_grammemes = sorted(self.all_grammemes.items(), key=lambda x: x[0])\n",
    "        for category, values in sorted_grammemes:\n",
    "            if category not in gram_tags:\n",
    "                vector += [1 if value == GrammemeVectorizer.UNKNOWN_VALUE else 0 for value in sorted(list(values))]\n",
    "            else:\n",
    "                vector += [1 if value == gram_tags[category] else 0 for value in sorted(list(values))]\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from russian_tagsets import converters\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "to_ud = converters.converter('opencorpora-int', 'ud14')\n",
    "\n",
    "def convert_from_opencorpora_tag(tag, text):\n",
    "    ud_tag = to_ud(str(tag), text)\n",
    "    pos = ud_tag.split()[0]\n",
    "    gram = ud_tag.split()[1]\n",
    "    return pos, gram\n",
    "\n",
    "def fill_all_variants(word, vectorizer):\n",
    "    for parse in morph.parse(word):\n",
    "        pos, gram = convert_from_opencorpora_tag(parse.tag, parse.word)\n",
    "        gram = process_gram_tag(gram)\n",
    "        vectorizer.add_grammemes(pos, gram)\n",
    "\n",
    "vectorizer = GrammemeVectorizer(\"vectorizer.json\")\n",
    "if vectorizer.is_empty():\n",
    "    for sentence in train:\n",
    "        for form in sentence:\n",
    "            fill_all_variants(form.word, vectorizer) \n",
    "    for sentence in test:\n",
    "        for word in sentence:\n",
    "            fill_all_variants(word, vectorizer)\n",
    "    vectorizer.init_possible_vectors()\n",
    "    vectorizer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_output = GrammemeVectorizer(\"vectorizer_output.json\")\n",
    "if vectorizer_output.is_empty():\n",
    "    for sentence in train:\n",
    "        for form in sentence:\n",
    "            gram = process_gram_tag(form.gram)\n",
    "            vectorizer_output.add_grammemes(form.pos, gram)\n",
    "    vectorizer_output.init_possible_vectors()\n",
    "    vectorizer_output.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Получение признаков для конкретного контекста.\n",
    "def get_context_features(i, parse_sentence, context_len):\n",
    "    sample = []\n",
    "    left = i-(context_len-1)//2\n",
    "    right = i+context_len//2\n",
    "    if left < 0:\n",
    "        for i in range(-left):\n",
    "            sample += [0 for i in range(vectorizer.grammemes_count())]\n",
    "    for parse in parse_sentence[max(left, 0): min(right+1, len(sentence))]:\n",
    "        word = parse.word\n",
    "        pos, gram = convert_from_opencorpora_tag(parse.tag, parse.word)\n",
    "        gram = process_gram_tag(gram)\n",
    "        sample += vectorizer.get_vector(pos+\"#\"+gram)\n",
    "    if right > len(sentence)-1:\n",
    "        for i in range(right-len(sentence)+1):\n",
    "            sample += [0 for i in range(vectorizer.grammemes_count())]\n",
    "    assert len(sample) == context_len * vectorizer.grammemes_count()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False  True False False\n",
      " False False False False  True False False  True False False False  True\n",
      " False False  True False  True False False False  True False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False  True False False False  True False  True False False\n",
      " False False  True False False  True False False  True False False  True\n",
      " False False False False False False  True False False  True False False\n",
      " False  True False False  True False  True False False False  True False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False  True False False False  True False  True\n",
      " False False False False  True False False  True False False  True False\n",
      " False  True False False False False False False  True False False  True\n",
      " False False False  True False False  True False  True False False False\n",
      "  True False  True False False False False False False False False False\n",
      " False False False False False False False  True False False False  True\n",
      " False  True False False False False  True False False  True] 0\n"
     ]
    }
   ],
   "source": [
    "# Загрузка обучающей выборки.\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TRAIN_SAMPLES_PATH = \"samples.npy\"\n",
    "ANSWERS_PATH = \"answers.npy\"\n",
    "if not os.path.exists(TRAIN_SAMPLES_PATH) or not os.path.exists(ANSWERS_PATH):\n",
    "    context_len = 5\n",
    "    n = sum([1 for sentence in train for word in sentence])\n",
    "    samples = np.zeros((n, context_len*vectorizer.grammemes_count()), dtype='bool_')\n",
    "    answers = np.zeros((n, ), dtype='int')\n",
    "    index = 0\n",
    "    for sentence in train:\n",
    "        parse_sentence = [morph.parse(form.word)[0] for form in sentence]\n",
    "        for i, form in enumerate(sentence):\n",
    "            samples[index] = get_context_features(i, parse_sentence , context_len)\n",
    "            gram = process_gram_tag(form.gram)\n",
    "            answers[index] = vectorizer_output.get_index_by_name(form.pos+\"#\"+gram)\n",
    "            index += 1\n",
    "            if index % 100000 == 0:\n",
    "                print(index)\n",
    "    np.save(TRAIN_SAMPLES_PATH, samples)\n",
    "    np.save(ANSWERS_PATH, answers)\n",
    "else:\n",
    "    samples = np.load(TRAIN_SAMPLES_PATH)\n",
    "    answers = np.load(ANSWERS_PATH)\n",
    "print(samples[0], answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузка тестовой выборки\n",
    "TEST_SAMPLES_PATH = \"test_samples.npy\"\n",
    "ANSWERS_PATH = \"answers.npy\"\n",
    "if not os.path.exists(TEST_SAMPLES_PATH):\n",
    "    n = sum([1 for sentence in test for word in sentence])\n",
    "    test_samples = np.zeros((n, context_len*vectorizer.grammemes_count()), dtype='bool_')\n",
    "    index = 0\n",
    "    for i, sentence in enumerate(test):\n",
    "        parse_sentence = [morph.parse(word)[0] for word in sentence]\n",
    "        for i, word in enumerate(sentence):\n",
    "            test_samples[index] = get_context_features(i, parse_sentence, context_len)\n",
    "            index += 1\n",
    "    np.save(TEST_SAMPLES_PATH, test_samples)\n",
    "else:\n",
    "    test_samples = np.load(TEST_SAMPLES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '4816' (I am process '14224')\n",
      "Using gpu device 0: GeForce GT 740M (CNMeM is enabled with initial size: 60.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(310,)),\n",
    "    Activation('relu'),\n",
    "    Dense(581),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                19904     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 581)               37765     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 581)               0         \n",
      "=================================================================\n",
      "Total params: 57,669.0\n",
      "Trainable params: 57,669.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.train_on_batch(samples[:100], answers[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = model.predict(samples[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_butch(dataX, dataY):\n",
    "    indexes = np.array(range(len(dataX)))\n",
    "    np.random.shuffle(indexes)\n",
    "    return dataX[indexes], dataY[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "epoch:  20\n",
      "epoch:  21\n",
      "epoch:  22\n",
      "epoch:  23\n",
      "epoch:  24\n"
     ]
    }
   ],
   "source": [
    "num_of_epoches = 25\n",
    "parts = [0,50000,100000,150000,200000,250000,300000,350000,400000,450000,500000,550000,600000,650000,700000,750000,800000,850688]\n",
    "for epoch in range(num_of_epoches):\n",
    "    print(\"epoch: \", epoch)\n",
    "    for i in range(len(parts) - 1):\n",
    "#         print(\"parts: \",parts[i],' - ', parts[i+1])\n",
    "        X, Y = shuffle_butch(samples[parts[i]:parts[i+1]], answers[parts[i]:parts[i+1]])\n",
    "        model.train_on_batch(X, Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217794, 310)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = model.predict(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_indexes = []\n",
    "for answer_part in answer:\n",
    "    answer_indexes.append(np.argmax(answer_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 2, 88, 9, 9, 22, 2, 11, 11]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_indexes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обучение классификатора.\n",
    "X = samples[:200000]\n",
    "y = answers[:200000]\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Предсказания.\n",
    "answers = []\n",
    "batch_size = 1000\n",
    "n_batches = len(test_samples)//batch_size\n",
    "for i in range(n_batches):\n",
    "    answers += list(clf.predict(test_samples[i*batch_size: i*batch_size+batch_size]))\n",
    "answers += list(clf.predict(test_samples[n_batches*batch_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Сохранение посылки\n",
    "with open(\"subm.csv\", \"w\") as f: \n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    for index, answer in enumerate(answer_indexes):\n",
    "        f.write(str(index) + \",\" + vectorizer_output.get_name_by_index(answer) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
